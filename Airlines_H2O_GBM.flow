{
  "version": "1.0.0",
  "cells": [
    {
      "type": "md",
      "input": "### * **Welcome to H2O Flow!** *\n\n# How to Predict Airline Delays\n\n#### In this demo we will show you how to:\n\n* **Import a dataset**\n\n* **Parse the dataset's contents**\n\n* **Split your dataset into a training and validation set (more on this later)**\n\n* **Build a model to predict whether or not a flight will be delayed**\n\n* **Evaluate the model's performance**\n\n### How to use the demo\na) you can run all the cells at once by clicking on the double arrowheads next to the question mark in the symbols menu bar at the top of the page\n\nb) or you can click on individual cells and press shift + enter to run a cell (for more information read through the help menu on the left panel)\n\n**Note:** The demo is written so that you do not need to interact with any of the *Action* buttons, however, if you do click a button - to further explore the data - the new cell will appear at the bottom of the page. You can move this new cell up or down using the up or down arrows in the symbols menu bar.\n\n### Short summary of the dataset\n* binary classification problem: predict if a flight is delayed\n* features are real, integer, and categorical\n"
    },
    {
      "type": "md",
      "input": "### Detail Summary of the Dataset\n\nThe following is a demonstration of predicting potential flight delays using a publicly available airlines dataset. For this example, the dataset used is a small sample of what is more than two decades worth of flight data in order to ensure the download and import process would not take more than a minute or two.\n\n### The Data\n\nThe data comes originally from [RITA](http://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp) where it is described in detail. To use the entire 26 years worth of flight information to more accurately predict delays and cancellation please download one of the following and change the path to the data in the notebook: \n\n  * [2 Thousand Rows - 4.3MB](https://s3.amazonaws.com/h2o-airlines-unpacked/allyears2k.csv)\n  * [5.8 Million Rows - 580MB](https://s3.amazonaws.com/h2o-airlines-unpacked/airlines_all.05p.csv)\n  * [152 Million Rows (Years: 1987-2013) - 14.5GB](https://s3.amazonaws.com/h2o-airlines-unpacked/allyears.1987.2013.csv)\n\n### Business Benefits\n\nThere are obvious benefits to predicting potential delays and logistic issues for a business. It helps the user make contingency plans and corrections to avoid undesirable outcomes. Recommendation engines can forewarn flyers of possible delays and rank flight options accordingly, other businesses might pay more for a flight to ensure certain shipments arrive on time, and airline carriers can use the information to better their flight plans. The goal is to have the machine take in all the possible factors that will affect a flight and return the probability of a flight being delayed."
    },
    {
      "type": "md",
      "input": "### Step 1) \n#### Import your File\nIn the cell below we import the Airlines dataset. This dataset predicts whether a flight will be delayed or not based of characteristics of the flight, for example where the airport a flight leaves from.\n\n**Note:** If you do not want to download the dataset from Amazon S3, simply comment out this line, then uncomment the line below, which gives an example of a local path, and replace the local path with the path to your dataset."
    },
    {
      "type": "cs",
      "input": "importFiles"
    },
    {
      "type": "cs",
      "input": "# importFiles [ \"http://h2o-public-test-data.s3.amazonaws.com/smalldata/airlines/allyears2k_headers.zip\" ]\nimportFiles [ \"/Users/laurend/Desktop/meetup_10:25/allyears2k_headers.zip\" ]"
    },
    {
      "type": "md",
      "input": "### Step 2)\n#### Parse the File\nH2O Flow parses the csv categorizing each column as a Numeric or Enum (an enum is a categorical feature, this lets the algorithm know each number represents a group not a real number). If the parser mislabels a column you can change the value using the drop-down menu. In this case, we will change a few columns from Numeric to Enum."
    },
    {
      "type": "cs",
      "input": "# setupParse source_frames: [ \"http://h2o-public-test-data.s3.amazonaws.com/smalldata/airlines/allyears2k_headers.zip\" ]\nsetupParse source_frames: [ \"nfs://Users/laurend/Desktop/meetup_10:25/allyears2k_headers.zip\" ]\n"
    },
    {
      "type": "cs",
      "input": "parseFiles\n  source_frames: [\"nfs://Users/laurend/Desktop/meetup_10:25/allyears2k_headers.zip\"]\n  destination_frame: \"allyears2k_headers1.hex\"\n  parse_type: \"CSV\"\n  separator: 44\n  number_columns: 31\n  single_quotes: false\n  column_names: [\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\",\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\",\"UniqueCarrier\",\"FlightNum\",\"TailNum\",\"ActualElapsedTime\",\"CRSElapsedTime\",\"AirTime\",\"ArrDelay\",\"DepDelay\",\"Origin\",\"Dest\",\"Distance\",\"TaxiIn\",\"TaxiOut\",\"Cancelled\",\"CancellationCode\",\"Diverted\",\"CarrierDelay\",\"WeatherDelay\",\"NASDelay\",\"SecurityDelay\",\"LateAircraftDelay\",\"IsArrDelayed\",\"IsDepDelayed\"]\n  column_types: [\"Enum\",\"Enum\",\"Enum\",\"Enum\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Enum\",\"Enum\",\"Enum\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Enum\",\"Enum\",\"Numeric\",\"Numeric\",\"Numeric\",\"Enum\",\"Enum\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Enum\",\"Enum\"]\n  delete_on_done: true\n  check_header: 1\n  chunk_size: 22156940"
    },
    {
      "type": "cs",
      "input": "getFrameSummary \"allyears2k_headers1.hex\""
    },
    {
      "type": "md",
      "input": "### Distributions\nYou can look at the distribution of a feature column by clicking on its name in the COLUMN SUMMARIES table above. After clicking on a column's name, a new cell will apear with a characterics bar, boxplot, and histogram.\n\nLet's take a look at the response column \"IsDepDelayed\". From the bar chart we can see that there is almost an even split in samples of flights that are delayed and on time. The characteristics bar shows us we also have a near even split of zeros to 'Yes' and 'No' - the zeros likely represent missing values.\n\nClicking on the \"DayOfWeek\" column (enum) we can see that the majority of samples are of Thursday flights, and the minority are of Saturday, but overall we have a pretty even sampling of each day of the week. \n\n*Note: the characterics bar shows what proportion of the feature columns are missing, zeros, others, etc. Hover over it to see which color relates to which characteristic* "
    },
    {
      "type": "cs",
      "input": "getColumnSummary \"allyears2k_headers1.hex\", \"IsDepDelayed\""
    },
    {
      "type": "cs",
      "input": "getColumnSummary \"allyears2k_headers1.hex\", \"DayOfWeek\""
    },
    {
      "type": "md",
      "input": "### Step 3)\n#### Split the Data\nBefore we build a model, we want to split the dataset into training, validation, and test datasets. This way we can build a model using one dataset, see how the model performs on an other dataset, and make predictions on the remaining dataset. A good split to use is 70% for the training dataset, 15% for the validation dataset, and 15% for the test dataset."
    },
    {
      "type": "cs",
      "input": "assist splitFrame, \"allyears2k_headers1.hex\""
    },
    {
      "type": "cs",
      "input": "splitFrame \"allyears2k_headers1.hex\", [0.7,0.15], [\"allyears2k_headers1.hex_0.70_train\",\"allyears2k_headers1.hex_0.150_valid\",\"allyears2k_headers1.hex_0.150_test\"], 1234"
    },
    {
      "type": "md",
      "input": "### Step 4)\n#### Build Your Model\n* For this example we will use a GBM, but you could also choose from any of the other supervised learning algorithms that work for classification problems (i.e., Gradient Boosting Machine, Distributed Random Forest, Deep Learning, or Naive Bayes).\n\n* For the parameters we select the training_frame as the 70% split and the validation_frame as the 15% split, we leave the parameter nfolds alone because we already created our folds with the training and validation frames.\n\n* The response is \"IsDepDelayed\", which we are trying to predict.\n\n* Because we don't want to leak the solutions to our model, we will also ignore a few columns that correspond to delayed flights."
    },
    {
      "type": "cs",
      "input": "assist buildModel, null, training_frame: \"allyears2k_headers1.hex\""
    },
    {
      "type": "cs",
      "input": "buildModel 'gbm', {\"model_id\":\"Airlines_GBM\",\"training_frame\":\"allyears2k_headers1.hex_0.70_train\",\"validation_frame\":\"allyears2k_headers1.hex_0.150_valid\",\"nfolds\":0,\"response_column\":\"IsDepDelayed\",\"ignored_columns\":[\"DayofMonth\",\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\",\"TailNum\",\"ActualElapsedTime\",\"CRSElapsedTime\",\"AirTime\",\"ArrDelay\",\"DepDelay\",\"TaxiIn\",\"TaxiOut\",\"Cancelled\",\"CancellationCode\",\"Diverted\",\"CarrierDelay\",\"WeatherDelay\",\"NASDelay\",\"SecurityDelay\",\"LateAircraftDelay\",\"IsArrDelayed\"], \"ignore_const_cols\":true,\"ntrees\":50,\"max_depth\":5,\"min_rows\":10,\"nbins\":20,\"seed\":-1,\"learn_rate\":0.1,\"sample_rate\":1,\"col_sample_rate\":1,\"score_each_iteration\":false,\"score_tree_interval\":0,\"balance_classes\":false,\"nbins_top_level\":1024,\"nbins_cats\":1024,\"r2_stopping\":1.7976931348623157e+308,\"stopping_rounds\":0,\"stopping_metric\":\"AUTO\",\"stopping_tolerance\":0.001,\"max_runtime_secs\":0,\"learn_rate_annealing\":1,\"distribution\":\"AUTO\",\"huber_alpha\":0.9,\"checkpoint\":\"\",\"col_sample_rate_per_tree\":1,\"min_split_improvement\":0.00001,\"histogram_type\":\"AUTO\",\"categorical_encoding\":\"AUTO\",\"build_tree_one_node\":false,\"sample_rate_per_class\":[],\"col_sample_rate_change_per_level\":1,\"max_abs_leafnode_pred\":1.7976931348623157e+308,\"pred_noise_bandwidth\":0}"
    },
    {
      "type": "md",
      "input": "### Step 5)\n#### Evaluate Your Model\n\n**Scoring History Plot:**\n\nThis plot shows how the logloss goes down as we increase the number of trees. We see that the validation dataset improves little after 20 trees. Notice how the training logloss keeps improving after 20 trees; this is an example of the model overfitting the data.\n\n*Logloss is a metric that penalises for misclassification. In general, the higher the logloss value the less accurate the model.*  \n\n**The ROC Plot:**\n\nThis plot shows the rate of true positives (tpr) against the rate of false positives (fpr). The red line is where the rates are equal. We see that the AUC for the validation set is 0.744635 - not bad - 1 would be a perfect score and .5 would be the same as guessing.\n\n**The Variable Importances Chart:**\n\nThis chart shows the relative importance of each feature. We see that the model thinks Origin, Year, and Destination are the most predictive features. On the other hand the model thinks Month and Distance are less relevant to predicting whether a flight will be delayed.\n"
    },
    {
      "type": "cs",
      "input": "getModel \"Airlines_GBM\""
    },
    {
      "type": "md",
      "input": "### Step 6)\n#### Make a Prediction\nThis is the step where you would make predictions on a dataset without the answers. In our toy dataset we do know the answers, but we will pretend like we don't. \n\n**Note**: If you pass a test dataset with the response column the algorithm will ignore it; it only pays attention to the features columns."
    },
    {
      "type": "cs",
      "input": "getFrameData \"allyears2k_headers1.hex_0.150_test\"\n# Instead of remembering the command above, 'getFrameData \"BostonHousing.hex_0.150_validation\"', you can also view the original test dataset by first clicking on 'List All Frames' under Data in the top menu bar, second clicking on the linked ID 'BostonHousing.hex_0.150_test', which will show you a summary of the dataset, and third clicking on the 'View Data' *Action* button."
    }
  ]
}